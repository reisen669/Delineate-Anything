{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffacf62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from osgeo import gdal\n",
    "import numpy as np\n",
    "from utils import *\n",
    "from IDMapper import IDMapper\n",
    "from TileLoader import TileLoader\n",
    "import logging\n",
    "import cv2\n",
    "from tqdm import tqdm  # For progress bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ea82f4",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Setup logger for better visibility\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46825422",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def delineate(model, tiff_path, field_id_counter, config):\n",
    "    logger.info(f\"Starting delineation of {tiff_path}\")\n",
    "\n",
    "    loader = TileLoader(\n",
    "        tiff_path,\n",
    "        tileDim=config[\"TILE_DIMENSIONS\"],\n",
    "        tileStep=config[\"TILE_STEP\"],\n",
    "        batchSize=config[\"BATCH_SIZE\"],\n",
    "        skip_tiles_with_nodata=config[\"SKIP_TILES_WITH_NODATA\"],\n",
    "        nodataValue=config[\"NODATA_VALUE\"],\n",
    "        alphaBand=config[\"ALPHA_BAND\"]\n",
    "    )\n",
    "\n",
    "    src_ds = loader.dataSource\n",
    "    scale_factor = 2 if loader.tileDim == 256 else 1\n",
    "    boundary_width = (loader.tileDim - loader.tileStep) * scale_factor\n",
    "\n",
    "    temp_instances_tiff_path = os.path.join(\n",
    "        config[\"TEMP_FOLDER_PATH\"],\n",
    "        os.path.basename(tiff_path).replace(\".tif\", \".instances.tif\")\n",
    "    )\n",
    "    temp_confidence_tiff_path = os.path.join(\n",
    "        config[\"TEMP_FOLDER_PATH\"],\n",
    "        os.path.basename(tiff_path).replace(\".tif\", \".confidence.tif\")\n",
    "    )\n",
    "    \n",
    "    pixel_offset_x = config[\"PIXEL_OFFSET_X\"]\n",
    "    pixel_offset_y = config[\"PIXEL_OFFSET_Y\"]\n",
    "    instance_raster = create_tiff_with_same_bounds(\n",
    "        temp_instances_tiff_path, src_ds, gdal.GDT_Int32, scale_factor, pixel_offset_x, pixel_offset_y\n",
    "    )\n",
    "    confidence_raster = create_tiff_with_same_bounds(\n",
    "        temp_confidence_tiff_path, src_ds, gdal.GDT_Float32, scale_factor, pixel_offset_x, pixel_offset_y\n",
    "    )\n",
    "\n",
    "    instance_band = instance_raster.GetRasterBand(1)\n",
    "    confidence_band = confidence_raster.GetRasterBand(1)\n",
    "\n",
    "    total_time = 0\n",
    "    dataloader_time = 0\n",
    "    model_time = 0\n",
    "    postproc_time = 0\n",
    "    mapping_time = 0\n",
    "\n",
    "    top_counter = 0\n",
    "    mappings = {}\n",
    "\n",
    "    # Try to get total_batches from the loader (if available)\n",
    "    total_batches = None\n",
    "    if hasattr(loader, 'estimated_batch_number'):\n",
    "        total_batches = loader.estimated_batch_number\n",
    "\n",
    "    # Use a tqdm progress bar for batch processing. If total_batches is None, the bar is indeterminate.\n",
    "    with tqdm(total=total_batches, desc=\"Number of batches\", unit=\" batch\") as pbar:\n",
    "        while True:\n",
    "            top_counter += 1\n",
    "            t_start = time.time()\n",
    "            batch_dict = loader.nextBatch()\n",
    "            batch = batch_dict[\"images\"]\n",
    "            nodata = batch_dict[\"nodata\"]\n",
    "            bounds = batch_dict[\"bounds\"]\n",
    "            if batch is None:\n",
    "                break\n",
    "            \n",
    "            t_end = time.time()\n",
    "            dataloader_time += t_end - t_start\n",
    "            total_time += t_end - t_start\n",
    "            \n",
    "            t_start = time.time()\n",
    "            results = model.predict(batch, conf=config[\"MINIMAL_CONFIDENCE\"], half=config[\"HALF\"], verbose=False)\n",
    "            t_end = time.time()\n",
    "            model_time += t_end - t_start\n",
    "            total_time += t_end - t_start\n",
    "\n",
    "            for i, result in enumerate(results):\n",
    "                if result.masks is None or len(result.masks) == 0:\n",
    "                    continue\n",
    "                \n",
    "                t_start = time.time()\n",
    "                nodata_mask = nodata[i].astype(\"uint8\")\n",
    "                nodata_mask = cv2.resize(nodata_mask, (512, 512), interpolation=cv2.INTER_NEAREST_EXACT)\n",
    "                nodata_mask = cv2.dilate(nodata_mask, np.ones((5, 5)))\n",
    "                nodata_mask = 1 - nodata_mask # invert to make 1 on data and 0 on nodata\n",
    "\n",
    "                instance_map, confidence_map, field_id_counter = rasterize(\n",
    "                    result, field_id_counter, \n",
    "                    config[\"PIXEL_AREA_THRESHOLD\"], \n",
    "                    config[\"REMAINING_AREA_THRESHOLD\"],\n",
    "                    nodata_mask\n",
    "                )\n",
    "\n",
    "                lhs, width, ths, height = bounds[i]\n",
    "                lhs *= scale_factor\n",
    "                width *= scale_factor\n",
    "                ths *= scale_factor\n",
    "                height *= scale_factor\n",
    "\n",
    "                existing_instances = instance_band.ReadAsArray(lhs + pixel_offset_x, ths + pixel_offset_y, width, height)\n",
    "                existing_confidence = confidence_band.ReadAsArray(lhs + pixel_offset_x, ths + pixel_offset_y, width, height)\n",
    "                new_instances = instance_map[:height, :width]\n",
    "                new_confidence = confidence_map[:height, :width]\n",
    "\n",
    "                mappings = find_edge_mapping(\n",
    "                    existing_instances[:boundary_width, :],\n",
    "                    new_instances[:boundary_width, :],\n",
    "                    mappings,\n",
    "                    config[\"MERGE_RELATIVE_AREA_THRESHOLD\"],\n",
    "                    config[\"MERGE_ASYMETRIC_MERGING_PIXEL_AREA_THRESHOLD\"],\n",
    "                    config[\"MERGE_ASYMETRYC_MERGING_RELATIVE_AREA_THRESHOLD\"]\n",
    "                )\n",
    "                mappings = find_edge_mapping(\n",
    "                    existing_instances[:, :boundary_width],\n",
    "                    new_instances[:, :boundary_width],\n",
    "                    mappings,\n",
    "                    config[\"MERGE_RELATIVE_AREA_THRESHOLD\"],\n",
    "                    config[\"MERGE_ASYMETRIC_MERGING_PIXEL_AREA_THRESHOLD\"],\n",
    "                    config[\"MERGE_ASYMETRYC_MERGING_RELATIVE_AREA_THRESHOLD\"]\n",
    "                )\n",
    "\n",
    "                write_instances = new_instances.copy()\n",
    "                write_confidence = new_confidence.copy()\n",
    "                mask = (new_confidence > existing_confidence).astype(\"bool\")\n",
    "                write_instances = new_instances * mask + existing_instances * (~mask)\n",
    "                write_confidence = new_confidence * mask + existing_confidence * (~mask)\n",
    "\n",
    "                instance_band.WriteArray(write_instances, lhs + pixel_offset_x, ths + pixel_offset_y)\n",
    "                confidence_band.WriteArray(write_confidence, lhs + pixel_offset_x, ths + pixel_offset_y)\n",
    "                t_end = time.time()\n",
    "                postproc_time += t_end - t_start\n",
    "                total_time += t_end - t_start\n",
    "\n",
    "            # Update progress: if total_batches is known, the progress bar shows current batch / total.\n",
    "            pbar.update(1)\n",
    "    \n",
    "    logger.info(\"Delineation has been finished.\")\n",
    "\n",
    "    # Merging: use a tqdm progress bar for merging rows\n",
    "    t_start = time.time()\n",
    "    logger.info(\"Preparing for merging...\")\n",
    "    mapper = IDMapper()\n",
    "    for key in mappings.keys():\n",
    "        arr = mappings[key]\n",
    "        arr.append(key)\n",
    "        mapper.union(arr)\n",
    "    \n",
    "    mapp = mapper.get_mapping()\n",
    "    npmap = np.array([mapp[i] if i in mapp else i for i in range(field_id_counter + 1)])\n",
    "    \n",
    "    w = instance_raster.RasterXSize\n",
    "    with tqdm(total=instance_raster.RasterYSize, desc=\"Merging rows\", unit=\" row\") as pbar_merge:\n",
    "        for i in range(instance_raster.RasterYSize):\n",
    "            line = instance_band.ReadAsArray(0, i, w, 1)\n",
    "            line = npmap[line]\n",
    "            instance_band.WriteArray(line, 0, i)\n",
    "            pbar_merge.update(1)\n",
    "    \n",
    "    t_end = time.time()\n",
    "    mapping_time += t_end - t_start\n",
    "    total_time += t_end - t_start\n",
    "\n",
    "    logger.info(f\"Fields have been merged. Total time: {round(total_time, 1)} s\")\n",
    "    logger.info(f\"Data loader time: {round(dataloader_time, 1)} s\")\n",
    "    logger.info(f\"Model time: {round(model_time, 1)} s\")\n",
    "    logger.info(f\"Postprocess time: {round(postproc_time, 1)} s\")\n",
    "    logger.info(f\"Merging (mapping) time: {round(mapping_time, 1)} s\")\n",
    "    logger.info(\"-------------------\")\n",
    "    \n",
    "    confidence_raster.FlushCache()\n",
    "    confidence_raster = None\n",
    "    instance_raster.FlushCache()\n",
    "    instance_raster = None\n",
    "    \n",
    "    return field_id_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a15ab7",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def multiple_source_merge(paths, field_id_counter, config):\n",
    "    total_time_start = time.time()\n",
    "\n",
    "    extents = []\n",
    "    for path in paths:\n",
    "        file = os.path.basename(path)\n",
    "        ds = gdal.Open(os.path.join(config[\"TEMP_FOLDER_PATH\"], file.replace(\".tif\", \".instances.tif\")))\n",
    "        extents.append(get_extent(ds))\n",
    "        projection = ds.GetProjection()\n",
    "        pixel_size = ds.GetGeoTransform()[1]\n",
    "    \n",
    "    total_extent = merge_extents(extents)\n",
    "    \n",
    "    instances_output_path = config[\"OUTPUT_TEMP_RASTER_PATH\"].replace(\".tif\", \".instances.tif\")\n",
    "    ds_instances = create_empty_tiff(instances_output_path, total_extent, projection, pixel_size, gdal.GDT_Int32)\n",
    "    ds_confidence = create_empty_tiff(\n",
    "        config[\"OUTPUT_TEMP_RASTER_PATH\"].replace(\".tif\", \".confidence.tif\"),\n",
    "        total_extent, projection, pixel_size, gdal.GDT_Float32\n",
    "    )\n",
    "    \n",
    "    band_instances = ds_instances.GetRasterBand(1)\n",
    "    band_confidence = ds_confidence.GetRasterBand(1)\n",
    "    \n",
    "    mappings = {}\n",
    "    # Use a tqdm progress bar for processing each file\n",
    "    for path in tqdm(paths, desc=\"Processing files for merge\", unit=\" file\"):\n",
    "        local_time_start = time.time()\n",
    "        file = os.path.basename(path)\n",
    "        \n",
    "        loader_instances = TileLoader(\n",
    "            os.path.join(config[\"TEMP_FOLDER_PATH\"], file.replace(\".tif\", \".instances.tif\")),\n",
    "            config[\"TILE_DIMENSIONS\"], config[\"TILE_STEP\"], 1, None, tileBands=1, dtype=\"int32\"\n",
    "        )\n",
    "        loader_confidence = TileLoader(\n",
    "            os.path.join(config[\"TEMP_FOLDER_PATH\"], file.replace(\".tif\", \".confidence.tif\")),\n",
    "            config[\"TILE_DIMENSIONS\"], config[\"TILE_STEP\"], 1, None, tileBands=1, dtype=\"float32\"\n",
    "        )\n",
    "        \n",
    "        offset_x, offset_y = get_pixel_offset(ds_instances, loader_instances.dataSource)\n",
    "        # Try to get total batches for this file, if available\n",
    "        total_batches_file = None\n",
    "        if hasattr(loader_instances, 'tiles'):\n",
    "            total_batches_file = int(np.ceil(len(loader_instances.tiles) / config[\"BATCH_SIZE\"]))\n",
    "        \n",
    "        with tqdm(total=total_batches_file, desc=f\"Mapping {file}\", unit=\" batch\") as pbar_file:\n",
    "            while True:\n",
    "                batch_instances = loader_instances.nextBatch()\n",
    "                batch_confidence = loader_confidence.nextBatch()\n",
    "                if batch_instances[\"images\"] is None:\n",
    "                    break\n",
    "                \n",
    "                instances = batch_instances[\"images\"][0].squeeze(2)\n",
    "                confidence = batch_confidence[\"images\"][0].squeeze(2)\n",
    "                lhs, width, ths, height = batch_confidence[\"bounds\"][0]\n",
    "                \n",
    "                old_instances = band_instances.ReadAsArray(offset_x + lhs, offset_y + ths, width, height)\n",
    "                old_confidence = band_confidence.ReadAsArray(offset_x + lhs, offset_y + ths, width, height)\n",
    "                \n",
    "                mappings = find_edge_mapping(\n",
    "                    old_instances[:height, :width],\n",
    "                    instances[:height, :width],\n",
    "                    mappings,\n",
    "                    config[\"MERGE_RELATIVE_AREA_THRESHOLD\"],\n",
    "                    config[\"MERGE_ASYMETRIC_MERGING_PIXEL_AREA_THRESHOLD\"],\n",
    "                    config[\"MERGE_ASYMETRYC_MERGING_RELATIVE_AREA_THRESHOLD\"]\n",
    "                )\n",
    "                \n",
    "                mask = (confidence[:height, :width] > old_confidence[:height, :width]).astype(\"bool\")\n",
    "                write_instances = instances[:height, :width] * mask + old_instances[:height, :width] * (~mask)\n",
    "                write_confidence = confidence[:height, :width] * mask + old_confidence[:height, :width] * (~mask)\n",
    "                \n",
    "                band_instances.WriteArray(write_instances[:height, :width], offset_x + lhs, offset_y + ths)\n",
    "                band_confidence.WriteArray(write_confidence[:height, :width], offset_x + lhs, offset_y + ths)\n",
    "                pbar_file.update(1)\n",
    "            # End of file batches loop\n",
    "        \n",
    "    logger.info(\"Images have been pre-merged.\")\n",
    "    \n",
    "    mapper = IDMapper()\n",
    "    for key in mappings.keys():\n",
    "        arr = mappings[key]\n",
    "        arr.append(key)\n",
    "        mapper.union(arr)\n",
    "    \n",
    "    mapp = mapper.get_mapping()\n",
    "    npmap = np.array([mapp[i] if i in mapp else i for i in range(field_id_counter + 1)])\n",
    "    \n",
    "    logger.info(\"Id mapping has been created.\")\n",
    "    \n",
    "    w = ds_instances.RasterXSize\n",
    "    with tqdm(total=ds_instances.RasterYSize, desc=\"Final merging rows\", unit=\" row\") as pbar_merge:\n",
    "        for i in range(ds_instances.RasterYSize):\n",
    "            line = band_instances.ReadAsArray(0, i, w, 1)\n",
    "            line = npmap[line]\n",
    "            band_instances.WriteArray(line, 0, i)\n",
    "            pbar_merge.update(1)\n",
    "    \n",
    "    ds_instances.FlushCache()\n",
    "    ds_confidence.FlushCache()\n",
    "    \n",
    "    logger.info(f\"Merging has been finished in {time.time() - total_time_start} s.\")\n",
    "    \n",
    "    return instances_output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de26baf",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def progress_callback(complete, message, user_data):\n",
    "    # Update tqdm progress bar if provided; otherwise, log info.\n",
    "    if user_data is not None and isinstance(user_data, dict) and \"pbar\" in user_data:\n",
    "        pbar = user_data[\"pbar\"]\n",
    "        pbar.n = int(complete * 100)\n",
    "        pbar.refresh()\n",
    "    else:\n",
    "        logger.info(f\"Polygonizing... {round(complete * 100, 1)} %\")\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1bcff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def polygonize(src_path, dst_path, config):\n",
    "    t_start = time.time()\n",
    "    \n",
    "    instance_raster = gdal.Open(src_path)\n",
    "    instance_band = instance_raster.GetRasterBand(1)\n",
    "    \n",
    "    # Setup a tqdm progress bar for polygonization (0 to 100%)\n",
    "    with tqdm(total=100, desc=\"Polygonizing\", unit=\"%\") as pbar:\n",
    "        user_data = {\"pbar\": pbar}\n",
    "        gpkg, layer = create_geopackage_with_same_projection(\n",
    "            dst_path, config[\"LAYER_NAME\"], instance_raster,\n",
    "            override_if_exists=config[\"OVERRIDE_IF_EXISTS\"]\n",
    "        )\n",
    "        gdal.Polygonize(instance_band, instance_band, layer, -1, [\"CONNECTED=4\"],\n",
    "                        callback=lambda complete, msg, u: progress_callback(complete, msg, user_data))\n",
    "    \n",
    "    instance_raster.FlushCache()\n",
    "    instance_raster = None\n",
    "    t_elapsed = time.time() - t_start\n",
    "    logger.info(f\"Polygonization has been completed in {t_elapsed} s.\")\n",
    "    cleanup_geopackage(layer, config[\"VECTORIZED_AREA_THRESHOLD\"])\n",
    "    logger.info(\"Geopackage cleaned up.\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
